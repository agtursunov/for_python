{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Scrape job listings from the website https://realpython.github.io/fake-jobs and store the data into an SQLite database.\n",
    "\n",
    "1. **Scraping Requirements**:\n",
    "   - Extract the following details for each job listing:\n",
    "     - **Job Title**\n",
    "     - **Company Name**\n",
    "     - **Location**\n",
    "     - **Job Description**\n",
    "     - **Application Link**\n",
    "\n",
    "2. **Data Storage**:\n",
    "   - Store the scraped data into an SQLite database in a table named `jobs`.\n",
    "\n",
    "3. **Incremental Load**:\n",
    "   - Ensure that your script performs **incremental loading**:\n",
    "     - Scrape the webpage and add only **new job listings** to the database.\n",
    "     - Avoid duplicating entries. Use `Job Title`, `Company Name`, and `Location` as unique identifiers for comparison.\n",
    "\n",
    "4. **Update Tracking**:\n",
    "   - Add functionality to detect if an existing job listing has been updated (e.g., description or application link changes) and update the database record accordingly.\n",
    "\n",
    "5. **Filtering and Exporting**:\n",
    "   - Allow filtering job listings by **location** or **company name**.\n",
    "   - Write a function to export filtered results into a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as Bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data():\n",
    "    url = 'https://realpython.github.io/fake-jobs'\n",
    "    response = requests.get(url)\n",
    "    soup = Bs(response.content)\n",
    "\n",
    "    job_titles = soup.find_all(class_=\"title is-5\")\n",
    "    job_titles_list = []\n",
    "    for job_title in job_titles:\n",
    "        job_titles_list.append(job_title.get_text())\n",
    "\n",
    "    company_names = soup.find_all(class_ = \"subtitle is-6 company\")\n",
    "    comany_names_list = []\n",
    "    for company_name in company_names:\n",
    "        comany_names_list.append(company_name.get_text())\n",
    "\n",
    "    locations = soup.find_all(class_ = \"location\")\n",
    "    locations_list = []\n",
    "    for location in locations:\n",
    "        locations_list.append(location.get_text().strip())\n",
    "\n",
    "    links = soup.find_all(\"a\")\n",
    "    links_list = []\n",
    "    for link in links:\n",
    "        link_to_add = link.get('href')\n",
    "        if link_to_add != 'https://www.realpython.com':\n",
    "            links_list.append(link.get('href'))\n",
    "    return {\"jobs\": job_titles_list, \"companies\": comany_names_list, \"locations\": locations_list, \"links\": links_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect('Vacancys.db') as vacancy_base:\n",
    "    cursor = vacancy_base.cursor()\n",
    "    query = 'CREATE TABLE IF NOT EXISTS Jobs (\"Job Title\" text, \"Company Name\" text, \"Location\" text, \"Application Link\" text)'\n",
    "    cursor.execute(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
