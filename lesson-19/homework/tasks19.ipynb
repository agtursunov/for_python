{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Merging and Joining**\n",
    "1. **Inner Join on Chinook Database**\n",
    "   - Load the `chinook.db` database.\n",
    "   - Perform an inner join between the `customers` and `invoices` tables on the `CustomerId` column.\n",
    "   - Find the total number of invoices for each customer.\n",
    "\n",
    "2. **Outer Join on Movie Data**\n",
    "   - Load the `movie.csv` file.\n",
    "   - Create two smaller DataFrames:\n",
    "     - One with only `director_name` and `color`.\n",
    "     - Another with `director_name` and `num_critic_for_reviews`.\n",
    "   - Perform a left join and then a full outer join on `director_name`.\n",
    "   - Count how many rows are in the resulting DataFrames for each join type.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 Task 1\n",
    "def load_chinook():\n",
    "    try:\n",
    "        path = r'../data/chinook.db'\n",
    "        with sqlite3.connect(path) as connection:\n",
    "            customers = pd.read_sql(\n",
    "                'SELECT * from customers',\n",
    "                con = connection\n",
    "            )\n",
    "            invoices = pd.read_sql(\n",
    "                'SELECT * from invoices',\n",
    "                con = connection\n",
    "            )\n",
    "        return customers, invoices\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f'Error occured {e}')\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f'Unexpected error happen {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work_with_chinook(customers, invoices):\n",
    "    inner_join = customers.merge(invoices, how = 'inner', on = 'CustomerId')    \n",
    "    result = inner_join.groupby('CustomerId').agg({\n",
    "        'InvoiceId': 'nunique',\n",
    "        **{col: 'first' for col in inner_join.columns[0:13] if col != 'InvoiceId'}\n",
    "    })\n",
    "    result.rename(columns={'InvoiceId':'The total number of invoices'}, inplace=True)\n",
    "    return inner_join, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movie():\n",
    "    try:\n",
    "        path = r'../data/movie.csv'\n",
    "        if not os.path.exists(path):\n",
    "            print(f'File Not found at {path}')\n",
    "            return None\n",
    "        movie_data = pd.read_csv(path)\n",
    "        return movie_data\n",
    "    except Exception as e:\n",
    "        print(f'Unexpected error happen {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work_with_movies(movie_data):\n",
    "    dataFrame_colors = movie_data.loc[:, ['director_name', 'color']]\n",
    "    dataFrame_critics = movie_data.loc[:, ['director_name', 'num_critic_for_reviews']]\n",
    "    left_merged = dataFrame_colors.merge(dataFrame_critics, how = 'left', on = 'director_name')\n",
    "    outer_merged = dataFrame_colors.merge(dataFrame_critics, how = 'outer', on = 'director_name')\n",
    "    return left_merged.shape[0], outer_merged.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Grouping and Aggregating**\n",
    "1. **Grouped Aggregations on Titanic**\n",
    "   - Group passengers by `Pclass` and calculate the following:\n",
    "     - Average age.\n",
    "     - Total fare.\n",
    "     - Count of passengers.\n",
    "   - Save the results to a new DataFrame.\n",
    "\n",
    "2. **Multi-level Grouping on Movie Data**\n",
    "   - Group the movies by `color` and `director_name`.\n",
    "   - Find:\n",
    "     - Total `num_critic_for_reviews` for each group.\n",
    "     - Average `duration` for each group.\n",
    "\n",
    "3. **Nested Grouping on Flights**\n",
    "   - Group flights by `Year` and `Month` and calculate:\n",
    "     - Total number of flights.\n",
    "     - Average arrival delay (`ArrDelay`).\n",
    "     - Maximum departure delay (`DepDelay`).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_titanic():\n",
    "    try:\n",
    "        path = r'../data/titanic.xlsx'\n",
    "        titanic_data = pd.read_excel(path, sheet_name=0)\n",
    "        return titanic_data\n",
    "    except Exception as e:\n",
    "        print(f'Unexpected error happen {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_titanic(titanic_data):\n",
    "    titanic_statistics = titanic_data.groupby(by='Pclass').agg({\n",
    "        'Age':'mean',\n",
    "        'Fare':'sum',\n",
    "        'PassengerId':'nunique' }).reset_index()\n",
    "    titanic_statistics.rename(columns = {'PassengerId':'Number of passengers'}, inplace = 'True')\n",
    "    return titanic_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_movies(movie_data):\n",
    "    movie_statistics = movie_data.groupby(by=['director_name', 'color']).agg({\n",
    "        'num_critic_for_reviews':'sum',\n",
    "        'duration':'mean'}).reset_index()\n",
    "    return movie_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flights():\n",
    "    try:\n",
    "        path = r'../data/flights'\n",
    "        if not os.path.exists(path):\n",
    "            print(f'File not found in {path}')\n",
    "            return None\n",
    "        flights_data = pd.read_parquet(path)\n",
    "        return flights_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error occured {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_flights(flights_data):\n",
    "    flights_data.loc[:, 'Flights'] = pd.to_numeric(flights_data.loc[:, 'Flights'], errors='coerce')\n",
    "    flights_data.loc[:, 'ArrDelay'] = pd.to_numeric(flights_data.loc[:, 'ArrDelay'], errors='coerce')\n",
    "    flights_data.loc[:, 'DepDelay'] = pd.to_numeric(flights_data.loc[:, 'DepDelay'], errors='coerce')\n",
    "    statistics_flights = flights_data.groupby(by=['Year' ,'Month']).agg({\n",
    "        'Flights':'sum',\n",
    "        'ArrDelay':'sum',\n",
    "        'DepDelay':'sum' \n",
    "    })\n",
    "    return statistics_flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **Applying Functions**\n",
    "1. **Apply a Custom Function on Titanic**\n",
    "   - Write a function to classify passengers as `Child` (age < 18) or `Adult`.\n",
    "   - Use `apply` to create a new column, `Age_Group`, with these values.\n",
    "\n",
    "2. **Normalize Employee Salaries**\n",
    "   - Load the `employee.csv` file.\n",
    "   - Normalize the salaries within each department.\n",
    "\n",
    "3. **Custom Function on Movies**\n",
    "   - Write a function that returns `Short`, `Medium`, or `Long` based on the duration of a movie:\n",
    "     - `Short`: Less than 60 minutes.\n",
    "     - `Medium`: Between 60 and 120 minutes.\n",
    "     - `Long`: More than 120 minutes.\n",
    "   - Apply this function to classify movies in the `movie.csv` dataset.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_function_on_titanic(titanic_data):\n",
    "    def classify_func(age):\n",
    "        if age < 18:\n",
    "            return 'Child'\n",
    "        else:\n",
    "            return 'Adult'\n",
    "    titanic_data['Age_Group'] = titanic_data['Age'].apply(classify_func)\n",
    "    return titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_employee():\n",
    "    try:\n",
    "        path = r'../data/employee.csv'\n",
    "        if not os.path.exists(path):\n",
    "            print(f'File not found in {path}')\n",
    "            return None\n",
    "        employee_data = pd.read_csv(path)\n",
    "        return employee_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error occured {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_employee(employee_data):\n",
    "    employee_data['normalized_by_salaries'] = employee_data.groupby(by='DEPARTMENT')['BASE_SALARY'].transform(lambda x: (x - x.mean())/x.std())\n",
    "    return employee_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_functions_on_movie(movie_data):\n",
    "    def classify_movies(duration):\n",
    "        if duration < 60:\n",
    "            return 'Short'\n",
    "        elif duration > 120:\n",
    "            return 'Long'\n",
    "        else:\n",
    "            return 'Medium'\n",
    "    movie_data['Classify_by_duration'] = movie_data['duration'].apply(classify_movies)\n",
    "    return movie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Using `pipe`**\n",
    "1. **Pipeline on Titanic**\n",
    "   - Create a pipeline to:\n",
    "     - Filter passengers who survived (`Survived == 1`).\n",
    "     - Fill missing `Age` values with the mean.\n",
    "     - Create a new column, `Fare_Per_Age`, by dividing `Fare` by `Age`.\n",
    "\n",
    "2. **Pipeline on Flights**\n",
    "   - Create a pipeline to:\n",
    "     - Filter flights with a departure delay greater than 30 minutes.\n",
    "     - Add a column `Delay_Per_Hour` by dividing the delay by the scheduled flight duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work_with_titanic(titanic_data):\n",
    "    def filter_survived(titanic_data):\n",
    "        return titanic_data.loc[titanic_data['Survived'] == 1].copy()\n",
    "    def fill_missing_ages(titanic_data):\n",
    "        titanic_data['Age'] = titanic_data['Age'].fillna(titanic_data['Age'].mean())\n",
    "        return titanic_data\n",
    "    def fare_per_age(titanic_data):\n",
    "        titanic_data['Fare_Per_Age'] = titanic_data['Fare']/titanic_data['Age']\n",
    "        return titanic_data\n",
    "    titanic_data = titanic_data.pipe(filter_survived).pipe(fill_missing_ages).pipe(fare_per_age)\n",
    "    return titanic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Year\tQuarter\tMonth\tDayofMonth\tDayOfWeek\tFlightDate\tReporting_Airline\tDOT_ID_Reporting_Airline\tIATA_CODE_Reporting_Airline\tTail_Number\tFlight_Number_Reporting_Airline\tOriginAirportID\tOriginAirportSeqID\tOriginCityMarketID\tOrigin\tOriginCityName\tOriginState\tOriginStateFips\tOriginStateName\tOriginWac\tDestAirportID\tDestAirportSeqID\tDestCityMarketID\tDest\tDestCityName\tDestState\tDestStateFips\tDestStateName\tDestWac\tCRSDepTime\tDepTime\tDepDelay\tDepDelayMinutes\tDepDel15\tDepartureDelayGroups\tDepTimeBlk\tTaxiOut\tWheelsOff\tWheelsOn\tTaxiIn\tCRSArrTime\tArrTime\tArrDelay\tArrDelayMinutes\tArrDel15\tArrivalDelayGroups\tArrTimeBlk\tCancelled\tCancellationCode\tDiverted\tCRSElapsedTime\tActualElapsedTime\tAirTime\tFlights\tDistance\tDistanceGroup\tCarrierDelay\tWeatherDelay\tNASDelay\tSecurityDelay\tLateAircraftDelay\tFirstDepTime\tTotalAddGTime\tLongestAddGTime\tDivAirportLandings\tDivReachedDest\tDivActualElapsedTime\tDivArrDelay\tDivDistance\tDiv1Airport\tDiv1AirportID\tDiv1AirportSeqID\tDiv1WheelsOn\tDiv1TotalGTime\tDiv1LongestGTime\tDiv1WheelsOff\tDiv1TailNum\tDiv2Airport\tDiv2AirportID\tDiv2AirportSeqID\tDiv2WheelsOn\tDiv2TotalGTime\tDiv2LongestGTime\tDiv2WheelsOff\tDiv2TailNum\tDiv3Airport\tDiv3AirportID\tDiv3AirportSeqID\tDiv3WheelsOn\tDiv3TotalGTime\tDiv3LongestGTime\tDiv3WheelsOff\tDiv3TailNum\tDiv4Airport\tDiv4AirportID\tDiv4AirportSeqID\tDiv4WheelsOn\tDiv4TotalGTime\tDiv4LongestGTime\tDiv4WheelsOff\tDiv4TailNum\tDiv5Airport\tDiv5AirportID\tDiv5AirportSeqID\tDiv5WheelsOn\tDiv5TotalGTime\tDiv5LongestGTime\tDiv5WheelsOff\tDiv5TailNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work_with_flights(flights_data):\n",
    "    \n",
    "    def filter_delay(flights_data):\n",
    "        flights_data['DepDelay'] = pd.to_numeric(flights_data['DepDelay'])\n",
    "        return flights_data[(flights_data['DepDelay'] > 30) | (flights_data['DepDelay'] < -30)].copy()\n",
    "\n",
    "    def delay_per_hour(flights_data):\n",
    "        flights_data['DepDelay'] = pd.to_numeric(flights_data['DepDelay'])\n",
    "        flights_data['AirTime'] = pd.to_numeric(flights_data['AirTime'])\n",
    "        flights_data['Delay_Per_Hour'] = flights_data['DepDelay'] / flights_data['AirTime']\n",
    "        return flights_data\n",
    "\n",
    "    flights_data = flights_data.pipe(filter_delay).pipe(delay_per_hour)\n",
    "\n",
    "    return flights_data[['DepDelay', 'AirTime', 'DepDelayMinutes', 'Delay_Per_Hour']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
